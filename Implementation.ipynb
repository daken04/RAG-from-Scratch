{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8758194,"sourceType":"datasetVersion","datasetId":5244830}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## RAG pipeline from Scratch\n\n#### The Goal of RAG is to take information and pass it to an LLM so that it can generate output based on that information ","metadata":{}},{"cell_type":"markdown","source":"* Retrieval - Find relavent info from a query\n* Augmented - Augment out input to the LLM\n* Generation - Generative output from LLM","metadata":{}},{"cell_type":"markdown","source":"## STEPS\n\n1. Open a PDF document (even a collection of PDFs)\n2. Format the text of the PDF textbook ready for an embedding model.\n3. Embed all of the chunks of text in the textbook and turn them into numerical embeddings which can store for later.\n4. Build a retrieval system that uses vector search to find relevant chunck of text based ona aquery\n5. Create a prompt that incorporates the relevant pieces of text.\n6. Generat an answer to a query based on the passages of the textbook with an LLM","metadata":{}},{"cell_type":"code","source":"# downloading requirements\n!pip install PyMuPDF\n!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:27:37.033423Z","iopub.execute_input":"2024-06-22T12:27:37.033831Z","iopub.status.idle":"2024-06-22T12:28:10.510546Z","shell.execute_reply.started":"2024-06-22T12:27:37.033795Z","shell.execute_reply":"2024-06-22T12:28:10.509526Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting PyMuPDF\n  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting PyMuPDFb==1.24.3 (from PyMuPDF)\n  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\nDownloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\nSuccessfully installed PyMuPDF-1.24.5 PyMuPDFb-1.24.3\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1\nimport os\n\n# get pdf path\npdf_path = \"/kaggle/input/nutrition-rag/human-nutrition-text.pdf\"","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:28:21.685345Z","iopub.execute_input":"2024-06-22T12:28:21.686145Z","iopub.status.idle":"2024-06-22T12:28:21.691831Z","shell.execute_reply.started":"2024-06-22T12:28:21.686103Z","shell.execute_reply":"2024-06-22T12:28:21.690601Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Step 2\n\nimport fitz\nfrom tqdm.auto import tqdm \n\ndef text_formatter(text: str) ->str:\n    cleaned_text = text.replace(\"\\n\",\" \").strip()\n    \n    return cleaned_text\n\ndef open_and_read_pdf(pdf_path: str) -> list[dict]:\n    doc = fitz.open(pdf_path)\n    pages_and_texts = []\n    \n    for page_number, page in tqdm(enumerate(doc)):\n#         print(page_number)\n        text = page.get_text()\n        text = text_formatter(text=text)\n        pages_and_texts.append({\"page_number\": page_number - 41,\n                               \"page_char_count\": len(text),\n                               \"page_word_count\": len(text.split(\" \")),\n                               \"page_sentence_count_raw\": len(text.split(\".\")),\n                               \"page_token_count\": len(text)/4, # 1 toke  is ~4 characters\n                               \"text\":text})\n        \n    return pages_and_texts\n    \npages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\npages_and_texts[:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:28:25.797877Z","iopub.execute_input":"2024-06-22T12:28:25.798257Z","iopub.status.idle":"2024-06-22T12:28:29.610977Z","shell.execute_reply.started":"2024-06-22T12:28:25.798226Z","shell.execute_reply":"2024-06-22T12:28:29.609870Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4f494cb72f467bb38dc9a20f14a335"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[{'page_number': -41,\n  'page_char_count': 29,\n  'page_word_count': 4,\n  'page_sentence_count_raw': 1,\n  'page_token_count': 7.25,\n  'text': 'Human Nutrition: 2020 Edition'},\n {'page_number': -40,\n  'page_char_count': 0,\n  'page_word_count': 1,\n  'page_sentence_count_raw': 1,\n  'page_token_count': 0.0,\n  'text': ''}]"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(pages_and_texts)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:28:30.721461Z","iopub.execute_input":"2024-06-22T12:28:30.722116Z","iopub.status.idle":"2024-06-22T12:28:31.138452Z","shell.execute_reply.started":"2024-06-22T12:28:30.722082Z","shell.execute_reply":"2024-06-22T12:28:31.137120Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n0          -41               29                4                        1   \n1          -40                0                1                        1   \n2          -39              320               54                        1   \n3          -38              212               32                        3   \n4          -37              797              145                        3   \n\n   page_token_count                                               text  \n0              7.25                      Human Nutrition: 2020 Edition  \n1              0.00                                                     \n2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n3             53.00  Human Nutrition: 2020 Edition by University of...  \n4            199.25  Contents  Preface  University of Hawai‘i at Mā...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>page_char_count</th>\n      <th>page_word_count</th>\n      <th>page_sentence_count_raw</th>\n      <th>page_token_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-41</td>\n      <td>29</td>\n      <td>4</td>\n      <td>1</td>\n      <td>7.25</td>\n      <td>Human Nutrition: 2020 Edition</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-40</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-39</td>\n      <td>320</td>\n      <td>54</td>\n      <td>1</td>\n      <td>80.00</td>\n      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-38</td>\n      <td>212</td>\n      <td>32</td>\n      <td>3</td>\n      <td>53.00</td>\n      <td>Human Nutrition: 2020 Edition by University of...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-37</td>\n      <td>797</td>\n      <td>145</td>\n      <td>3</td>\n      <td>199.25</td>\n      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:28:31.934666Z","iopub.execute_input":"2024-06-22T12:28:31.935185Z","iopub.status.idle":"2024-06-22T12:28:31.965979Z","shell.execute_reply.started":"2024-06-22T12:28:31.935150Z","shell.execute_reply":"2024-06-22T12:28:31.964907Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\ncount   1208.00000      1208.000000      1208.000000              1208.000000   \nmean     562.50000      1148.594371       198.889901                14.180464   \nstd      348.86387       560.441673        95.747365                 9.544587   \nmin      -41.00000         0.000000         1.000000                 1.000000   \n25%      260.75000       762.750000       134.000000                 8.000000   \n50%      562.50000      1232.500000       215.000000                13.000000   \n75%      864.25000      1605.250000       271.250000                19.000000   \nmax     1166.00000      2308.000000       429.000000                82.000000   \n\n       page_token_count  \ncount       1208.000000  \nmean         287.148593  \nstd          140.110418  \nmin            0.000000  \n25%          190.687500  \n50%          308.125000  \n75%          401.312500  \nmax          577.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>page_char_count</th>\n      <th>page_word_count</th>\n      <th>page_sentence_count_raw</th>\n      <th>page_token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1208.00000</td>\n      <td>1208.000000</td>\n      <td>1208.000000</td>\n      <td>1208.000000</td>\n      <td>1208.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>562.50000</td>\n      <td>1148.594371</td>\n      <td>198.889901</td>\n      <td>14.180464</td>\n      <td>287.148593</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>348.86387</td>\n      <td>560.441673</td>\n      <td>95.747365</td>\n      <td>9.544587</td>\n      <td>140.110418</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-41.00000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>260.75000</td>\n      <td>762.750000</td>\n      <td>134.000000</td>\n      <td>8.000000</td>\n      <td>190.687500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>562.50000</td>\n      <td>1232.500000</td>\n      <td>215.000000</td>\n      <td>13.000000</td>\n      <td>308.125000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>864.25000</td>\n      <td>1605.250000</td>\n      <td>271.250000</td>\n      <td>19.000000</td>\n      <td>401.312500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1166.00000</td>\n      <td>2308.000000</td>\n      <td>429.000000</td>\n      <td>82.000000</td>\n      <td>577.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Splitting text in page into sentences, using NLP lib - spaCy\nfrom spacy.lang.en import English\n\nnlp = English()\nnlp.add_pipe(\"sentencizer\")\n\nfor item in tqdm(pages_and_texts):\n    item[\"sentences\"] = list(nlp(item['text']).sents)\n    \n    # Make sure all sentences are strings\n    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n    \n    #Count the sentences\n    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:28:48.252205Z","iopub.execute_input":"2024-06-22T12:28:48.252634Z","iopub.status.idle":"2024-06-22T12:29:01.215299Z","shell.execute_reply.started":"2024-06-22T12:28:48.252603Z","shell.execute_reply":"2024-06-22T12:29:01.214119Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1208 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab5b4ff763e04c81b129fb96055ac98d"}},"metadata":{}}]},{"cell_type":"code","source":"import random\n\nrandom.sample(pages_and_texts, k=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:01.217181Z","iopub.execute_input":"2024-06-22T12:29:01.217792Z","iopub.status.idle":"2024-06-22T12:29:01.225954Z","shell.execute_reply.started":"2024-06-22T12:29:01.217738Z","shell.execute_reply":"2024-06-22T12:29:01.224622Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'page_number': 75,\n  'page_char_count': 920,\n  'page_word_count': 160,\n  'page_sentence_count_raw': 9,\n  'page_token_count': 230.0,\n  'text': '“Segmentatio n” by  OpenStax  College / CC  BY 3.0  forward. Segmentation from circular muscle contraction slows  movement in the small intestine by forming temporary “sausage  link” type of segments that allows chyme to slosh food back and  forth in both directions to promote mixing of the chyme and  enhance absorption of nutrients (Figure 2.7 “Segmentation”). Almost  all the components of food are completely broken down to their  simplest units within the first 25 centimeters of the small intestine.  Instead of proteins, carbohydrates, and lipids, the chyme now  consists of amino acids, monosaccharides, and emulsified  components of triglycerides.  Figure 2.7 Segmentation  The third step of digestion (nutrient absorption) takes place mainly  in the remaining length of the small intestine, or ileum (> 5 meters).  The way the small intestine is structured gives it a huge surface  The Digestive System  |  75',\n  'sentences': ['“Segmentatio n” by  OpenStax  College / CC  BY 3.0  forward.',\n   'Segmentation from circular muscle contraction slows  movement in the small intestine by forming temporary “sausage  link” type of segments that allows chyme to slosh food back and  forth in both directions to promote mixing of the chyme and  enhance absorption of nutrients (Figure 2.7 “Segmentation”).',\n   'Almost  all the components of food are completely broken down to their  simplest units within the first 25 centimeters of the small intestine.',\n   ' Instead of proteins, carbohydrates, and lipids, the chyme now  consists of amino acids, monosaccharides, and emulsified  components of triglycerides.',\n   ' Figure 2.7 Segmentation  The third step of digestion (nutrient absorption) takes place mainly  in the remaining length of the small intestine, or ileum (> 5 meters).',\n   ' The way the small intestine is structured gives it a huge surface  The Digestive System  |  75'],\n  'page_sentence_count_spacy': 6}]"},"metadata":{}}]},{"cell_type":"code","source":"# STEP 3\n\n# Chucking our sentences together\n# Chucking - grouping sentences into groups\n\n# We do this because, to make our text chunks fit into our embedding model context window\n\nnum_sentence_chunk_size = 10\n\n# eg: [25] => [10,10,5] \n\ndef split_list(input_list:list[str],\n              slice_size: int=num_sentence_chunk_size) -> list[list[str]]:\n    return [input_list[i:i+slice_size] for i in range(0, len(input_list),slice_size)]\n\n# Testing\ntest_list = list(range(25))\nsplit_list(test_list)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:02.331190Z","iopub.execute_input":"2024-06-22T12:29:02.331639Z","iopub.status.idle":"2024-06-22T12:29:02.342339Z","shell.execute_reply.started":"2024-06-22T12:29:02.331588Z","shell.execute_reply":"2024-06-22T12:29:02.341139Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24]]"},"metadata":{}}]},{"cell_type":"code","source":"# Loop through pages and texts and split sentences into chunks\nfor item in tqdm(pages_and_texts):\n    item[\"sentence_chunks\"] = split_list(input_list = item[\"sentences\"],\n                                        slice_size=num_sentence_chunk_size)\n    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:03.735054Z","iopub.execute_input":"2024-06-22T12:29:03.735496Z","iopub.status.idle":"2024-06-22T12:29:03.766449Z","shell.execute_reply.started":"2024-06-22T12:29:03.735460Z","shell.execute_reply":"2024-06-22T12:29:03.765260Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1208 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f12f453f4c6a4c0fadf81a69bbb1979c"}},"metadata":{}}]},{"cell_type":"code","source":"random.sample(pages_and_texts, k=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:04.734901Z","iopub.execute_input":"2024-06-22T12:29:04.735285Z","iopub.status.idle":"2024-06-22T12:29:04.743338Z","shell.execute_reply.started":"2024-06-22T12:29:04.735239Z","shell.execute_reply":"2024-06-22T12:29:04.742205Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'page_number': 1020,\n  'page_char_count': 1502,\n  'page_word_count': 261,\n  'page_sentence_count_raw': 16,\n  'page_token_count': 375.5,\n  'text': 'Why Irradiate Food?  Irradiation can serve many purposes.  • Prevention of Foodborne Illness – to effectively eliminate  organisms that cause foodborne illness, such as Salmonella and  E. coli.  • Preservation – to destroy or inactivate organisms that cause  spoilage and decomposition and extend the shelf life of foods.  • Control of Insects – to destroy insects in or on tropical fruits  imported into the United States. Irradiation also decreases the  need for other pest-control practices that may harm the fruit.  • Delay of Sprouting and Ripening – to inhibit sprouting (e.g.,  potatoes) and delay ripening of fruit to increase longevity.  • Sterilization – irradiation can be used to sterilize foods, which  can then be stored for years without refrigeration. Sterilized  foods are useful in hospitals for patients with severely impaired  immune systems, such as patients with AIDS or undergoing  chemotherapy. Foods that are sterilized by irradiation are  exposed to substantially higher levels of treatment than those  approved for general use.  How Is Food Irradiated?  There are three sources of radiation approved for use on foods.  • Gamma rays are emitted from radioactive forms of the element  cobalt (Cobalt 60) or of the element cesium (Cesium 137).  Gamma radiation is used routinely to sterilize medical, dental,  and household products and is also used for the radiation  treatment of cancer.  • X-rays are produced by reflecting a high-energy stream of  1020  |  Food Preservation',\n  'sentences': ['Why Irradiate Food?',\n   ' Irradiation can serve many purposes.',\n   ' • Prevention of Foodborne Illness – to effectively eliminate  organisms that cause foodborne illness, such as Salmonella and  E. coli.',\n   ' • Preservation – to destroy or inactivate organisms that cause  spoilage and decomposition and extend the shelf life of foods.',\n   ' • Control of Insects – to destroy insects in or on tropical fruits  imported into the United States.',\n   'Irradiation also decreases the  need for other pest-control practices that may harm the fruit.',\n   ' • Delay of Sprouting and Ripening – to inhibit sprouting (e.g.,  potatoes) and delay ripening of fruit to increase longevity.',\n   ' • Sterilization – irradiation can be used to sterilize foods, which  can then be stored for years without refrigeration.',\n   'Sterilized  foods are useful in hospitals for patients with severely impaired  immune systems, such as patients with AIDS or undergoing  chemotherapy.',\n   'Foods that are sterilized by irradiation are  exposed to substantially higher levels of treatment than those  approved for general use.',\n   ' How Is Food Irradiated?',\n   ' There are three sources of radiation approved for use on foods.',\n   ' • Gamma rays are emitted from radioactive forms of the element  cobalt (Cobalt 60) or of the element cesium (Cesium 137).',\n   ' Gamma radiation is used routinely to sterilize medical, dental,  and household products and is also used for the radiation  treatment of cancer.',\n   ' • X-rays are produced by reflecting a high-energy stream of  1020  |  Food Preservation'],\n  'page_sentence_count_spacy': 15,\n  'sentence_chunks': [['Why Irradiate Food?',\n    ' Irradiation can serve many purposes.',\n    ' • Prevention of Foodborne Illness – to effectively eliminate  organisms that cause foodborne illness, such as Salmonella and  E. coli.',\n    ' • Preservation – to destroy or inactivate organisms that cause  spoilage and decomposition and extend the shelf life of foods.',\n    ' • Control of Insects – to destroy insects in or on tropical fruits  imported into the United States.',\n    'Irradiation also decreases the  need for other pest-control practices that may harm the fruit.',\n    ' • Delay of Sprouting and Ripening – to inhibit sprouting (e.g.,  potatoes) and delay ripening of fruit to increase longevity.',\n    ' • Sterilization – irradiation can be used to sterilize foods, which  can then be stored for years without refrigeration.',\n    'Sterilized  foods are useful in hospitals for patients with severely impaired  immune systems, such as patients with AIDS or undergoing  chemotherapy.',\n    'Foods that are sterilized by irradiation are  exposed to substantially higher levels of treatment than those  approved for general use.'],\n   [' How Is Food Irradiated?',\n    ' There are three sources of radiation approved for use on foods.',\n    ' • Gamma rays are emitted from radioactive forms of the element  cobalt (Cobalt 60) or of the element cesium (Cesium 137).',\n    ' Gamma radiation is used routinely to sterilize medical, dental,  and household products and is also used for the radiation  treatment of cancer.',\n    ' • X-rays are produced by reflecting a high-energy stream of  1020  |  Food Preservation']],\n  'num_chunks': 2}]"},"metadata":{}}]},{"cell_type":"code","source":"# Split each chunk into its own item\nimport re\n\n# Split each chunk into its own item\npages_and_chunks = []\nfor item in tqdm(pages_and_texts):\n    for sentence_chunk in item[\"sentence_chunks\"]:\n        chunk_dict = {}\n        chunk_dict[\"page_number\"] = item[\"page_number\"]\n        \n        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n\n        # Get stats about the chunk\n        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n        \n        pages_and_chunks.append(chunk_dict)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:05.665231Z","iopub.execute_input":"2024-06-22T12:29:05.666184Z","iopub.status.idle":"2024-06-22T12:29:05.763021Z","shell.execute_reply.started":"2024-06-22T12:29:05.666147Z","shell.execute_reply":"2024-06-22T12:29:05.761998Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1208 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f98216d0837453daffc637754733594"}},"metadata":{}}]},{"cell_type":"code","source":"# View a random sample\nrandom.sample(pages_and_chunks, k=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:06.605248Z","iopub.execute_input":"2024-06-22T12:29:06.605693Z","iopub.status.idle":"2024-06-22T12:29:06.613944Z","shell.execute_reply.started":"2024-06-22T12:29:06.605661Z","shell.execute_reply":"2024-06-22T12:29:06.612529Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'page_number': 152,\n  'sentence_chunk': 'Image by Allison Calabrese / CC BY 4.0 and negatively charged electrolytes are called anions. For example, in water sodium chloride (the chemical name for table salt) dissociates into sodium cations (Na+) and chloride anions (Cl−). Solutes refers to all dissolved substances in a fluid, which may be charged, such as sodium (Na+), or uncharged, such as glucose. In the human body, water and solutes are distributed into two compartments: inside cells, called intracellular, and outside cells, called extracellular. The extracellular water compartment is subdivided into the spaces between cells also known as interstitial, blood plasma, and other bodily fluids such as the cerebrospinal fluid which surrounds and protects the brain and spinal cord (Figure 3.2 “Distribution of Body Water”). The composition of solutes differs between the fluid compartments. For instance, more protein is inside cells than outside and more chloride anions exist outside of cells than inside. Figure 3.2 Distribution of Body Water Osmoregulation One of the essential homeostatic functions of the body is to maintain fluid balance and the differences in solute composition 152 | Overview of Fluid and Electrolyte Balance',\n  'chunk_char_count': 1201,\n  'chunk_word_count': 183,\n  'chunk_token_count': 300.25}]"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.DataFrame(pages_and_chunks)\ndf.describe().round(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:07.489636Z","iopub.execute_input":"2024-06-22T12:29:07.490037Z","iopub.status.idle":"2024-06-22T12:29:07.521618Z","shell.execute_reply.started":"2024-06-22T12:29:07.490005Z","shell.execute_reply":"2024-06-22T12:29:07.520609Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       page_number  chunk_char_count  chunk_word_count  chunk_token_count\ncount      1843.00           1843.00           1843.00            1843.00\nmean        583.38            734.83            112.72             183.71\nstd         347.79            447.43             71.07             111.86\nmin         -41.00             12.00              3.00               3.00\n25%         280.50            315.00             45.00              78.75\n50%         586.00            746.00            114.00             186.50\n75%         890.00           1118.50            173.00             279.62\nmax        1166.00           1831.00            297.00             457.75","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>chunk_char_count</th>\n      <th>chunk_word_count</th>\n      <th>chunk_token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1843.00</td>\n      <td>1843.00</td>\n      <td>1843.00</td>\n      <td>1843.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>583.38</td>\n      <td>734.83</td>\n      <td>112.72</td>\n      <td>183.71</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>347.79</td>\n      <td>447.43</td>\n      <td>71.07</td>\n      <td>111.86</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-41.00</td>\n      <td>12.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>280.50</td>\n      <td>315.00</td>\n      <td>45.00</td>\n      <td>78.75</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>586.00</td>\n      <td>746.00</td>\n      <td>114.00</td>\n      <td>186.50</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>890.00</td>\n      <td>1118.50</td>\n      <td>173.00</td>\n      <td>279.62</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1166.00</td>\n      <td>1831.00</td>\n      <td>297.00</td>\n      <td>457.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Show random chunks with under 30 tokens in length\nmin_token_length = 30\nfor row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:08.234961Z","iopub.execute_input":"2024-06-22T12:29:08.235365Z","iopub.status.idle":"2024-06-22T12:29:08.249612Z","shell.execute_reply.started":"2024-06-22T12:29:08.235335Z","shell.execute_reply":"2024-06-22T12:29:08.248323Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Chunk token count: 25.5 | Text: http:/ /pressbooks.oer.hawaii.edu/ humannutrition2/?p=521   996 | The Major Types of Foodborne Illness\nChunk token count: 13.0 | Text: US Department of Agriculture, 1136 | Food Insecurity\nChunk token count: 30.0 | Text: 2011.  https:/ /www.ers.usda.gov/publications/pub- details/?pubid=44909. Accessed April 15, 2018. 1138 | Food Insecurity\nChunk token count: 29.25 | Text: You can view it online here: http:/ /pressbooks.oer.hawaii.edu/ humannutrition2/?p=55   28 | Lifestyles and Nutrition\nChunk token count: 16.0 | Text: PART II CHAPTER 2. THE HUMAN BODY Chapter 2. The Human Body | 53\n","output_type":"stream"}]},{"cell_type":"code","source":"# filter our DataFrame for rows with under 30 tokens\n\npages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\npages_and_chunks_over_min_token_len[:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:09.004664Z","iopub.execute_input":"2024-06-22T12:29:09.005470Z","iopub.status.idle":"2024-06-22T12:29:09.023796Z","shell.execute_reply.started":"2024-06-22T12:29:09.005433Z","shell.execute_reply":"2024-06-22T12:29:09.022740Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[{'page_number': -39,\n  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n  'chunk_char_count': 308,\n  'chunk_word_count': 42,\n  'chunk_token_count': 77.0},\n {'page_number': -38,\n  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n  'chunk_char_count': 210,\n  'chunk_word_count': 30,\n  'chunk_token_count': 52.5}]"},"metadata":{}}]},{"cell_type":"code","source":"# Embedding our text chunks\n\n# using all-mpnet-base-v2 sentence transformer\n\n!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:09.744395Z","iopub.execute_input":"2024-06-22T12:29:09.744804Z","iopub.status.idle":"2024-06-22T12:29:24.687855Z","shell.execute_reply.started":"2024-06-22T12:29:09.744773Z","shell.execute_reply":"2024-06-22T12:29:24.686620Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.41.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n\nembedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2',\n                           device = \"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:24.690630Z","iopub.execute_input":"2024-06-22T12:29:24.691095Z","iopub.status.idle":"2024-06-22T12:29:46.525142Z","shell.execute_reply.started":"2024-06-22T12:29:24.691049Z","shell.execute_reply":"2024-06-22T12:29:46.523843Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2024-06-22 12:29:30.072123: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-22 12:29:30.072234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-22 12:29:30.230624: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"186f930ad73b4de686b8e4dca097bd7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78cd1ac802fa457d8608e1567204933a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088b7f4b57394528ab1c1ad75dae0952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465dff93f0764c8993a170d459b56d6b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d044d1fa2506479d8b9a7669251e4008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea1f30d0918f44d1aadc552111eeacf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"318d71f1587c4bcfa6e484a8d46b3dee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8d02393be34278a58a59fe06db9f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1327645d01de4aa4bb37a7208d74a2b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802c5da090c04d1b854522e93a1fd239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c51beff6494a6ab43faf0abd1250ee"}},"metadata":{}}]},{"cell_type":"code","source":"embed = embedding_model.encode(sentences)\n\nembed","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:36:59.454754Z","iopub.execute_input":"2024-06-22T12:36:59.455147Z","iopub.status.idle":"2024-06-22T12:36:59.509652Z","shell.execute_reply.started":"2024-06-22T12:36:59.455116Z","shell.execute_reply":"2024-06-22T12:36:59.508350Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f7359da8c647129fe1f0bfeafc60ad"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array([[ 0.0225026 , -0.07829171, -0.02303073, ..., -0.00827931,\n         0.02652686, -0.00201899],\n       [ 0.04170235,  0.00109742, -0.0155342 , ..., -0.02181628,\n        -0.0635936 , -0.00875286]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Turn text chunks into a single list\ntext_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]\n\ntext_chunks[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:36:29.766520Z","iopub.execute_input":"2024-06-22T12:36:29.766907Z","iopub.status.idle":"2024-06-22T12:36:29.774535Z","shell.execute_reply.started":"2024-06-22T12:36:29.766878Z","shell.execute_reply":"2024-06-22T12:36:29.773258Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE'"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\n# Embed all texts in batches\ntext_chunk_embeddings = embedding_model.encode(text_chunks)\ntext_chunk_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:37:40.591373Z","iopub.execute_input":"2024-06-22T12:37:40.592159Z","iopub.status.idle":"2024-06-22T12:37:41.730773Z","shell.execute_reply.started":"2024-06-22T12:37:40.592119Z","shell.execute_reply":"2024-06-22T12:37:41.729458Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/53 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88f00b0da414d97a10daa50c867b7cc"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m<timed exec>:2\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:545\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    544\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 545\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    554\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:335\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    333\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 335\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:294\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m ):\n\u001b[0;32m--> 294\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    302\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:235\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    228\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    234\u001b[0m ):\n\u001b[0;32m--> 235\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[1;32m    243\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:171\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(v)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Apply relative position embedding (precomputed in MPNetEncoder) if provided.\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Invalid argument"],"ename":"RuntimeError","evalue":"Invalid argument","output_type":"error"}]},{"cell_type":"code","source":"# Save embeddings to file\ntext_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\nembeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:49.601203Z","iopub.execute_input":"2024-06-22T12:29:49.603054Z","iopub.status.idle":"2024-06-22T12:29:49.619972Z","shell.execute_reply.started":"2024-06-22T12:29:49.603009Z","shell.execute_reply":"2024-06-22T12:29:49.618395Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"text_chunks_and_embeddings_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:49.622228Z","iopub.execute_input":"2024-06-22T12:29:49.623458Z","iopub.status.idle":"2024-06-22T12:29:49.799015Z","shell.execute_reply.started":"2024-06-22T12:29:49.623413Z","shell.execute_reply":"2024-06-22T12:29:49.797777Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(1680, 5)"},"metadata":{}}]},{"cell_type":"code","source":"len(text_chunk_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:49.805208Z","iopub.execute_input":"2024-06-22T12:29:49.805683Z","iopub.status.idle":"2024-06-22T12:29:50.186970Z","shell.execute_reply.started":"2024-06-22T12:29:49.805646Z","shell.execute_reply":"2024-06-22T12:29:50.185353Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtext_chunk_embeddings\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'text_chunk_embeddings' is not defined"],"ename":"NameError","evalue":"name 'text_chunk_embeddings' is not defined","output_type":"error"}]},{"cell_type":"code","source":"new_column_list_cpu = [tensor.cpu().numpy() for tensor in text_chunk_embeddings]\ntext_chunks_and_embeddings_df[\"embedding\"] = new_column_list_cpu\ntext_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:29:50.191127Z","iopub.status.idle":"2024-06-22T12:29:50.192152Z","shell.execute_reply.started":"2024-06-22T12:29:50.191833Z","shell.execute_reply":"2024-06-22T12:29:50.191863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import saved file and view\ntext_chunks_and_embedding_df = pd.read_csv(embeddings_df_save_path)\ntext_chunks_and_embedding_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### NOTE: In this notebook, Haven't used Vector databases\n\n*  In RAG, documents and queries are represented as high-dimensional vectors using embeddings\n* Vector databases, like FAISS, Milvus, or Pinecone, are optimized for performing efficient similarity searches. They can quickly find the nearest vectors (similar documents) to a given query vector using algorithms like Approximate Nearest Neighbors (ANN).\n\n#### Approximate Nearest Neighbors (ANN) Search:\n\n* Indexing: Before searching, the database creates an index using ANN algorithms. This index organizes the vectors in a way that makes it efficient to search for nearest neighbors.\n* Partitioning and Probing: The index partitions the vector space into multiple smaller regions or clusters. When a query is made, the search algorithm probes a subset of these regions that are most likely to contain similar vectors.\n* Reduced Comparisons: Instead of comparing the query vector against all 10M vectors, the search algorithm only compares it against vectors in the selected regions. For example, it might compare the query vector with 1 million (1M) vectors that are in the most promising regions.","metadata":{}},{"cell_type":"markdown","source":"## Run from here","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# STEP 4\n# RAG Search and Answer\n\n# Comparing embedding is called similarity search or vector search\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\ntext_chunks_and_embedding_df = pd.read_csv(\"/kaggle/input/nutrition-rag/text_chunks_and_embeddings_df.csv\")\ntext_chunks_and_embedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:38:26.376170Z","iopub.execute_input":"2024-06-22T12:38:26.377098Z","iopub.status.idle":"2024-06-22T12:38:26.869857Z","shell.execute_reply.started":"2024-06-22T12:38:26.377046Z","shell.execute_reply":"2024-06-22T12:38:26.868859Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   page_number                                     sentence_chunk  \\\n0          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n1          -38  Human Nutrition: 2020 Edition by University of...   \n2          -37  Contents Preface University of Hawai‘i at Māno...   \n3          -36  Lifestyles and Nutrition University of Hawai‘i...   \n4          -35  The Cardiovascular System University of Hawai‘...   \n\n   chunk_char_count  chunk_word_count  chunk_token_count  \\\n0               308                42              77.00   \n1               210                30              52.50   \n2               766               114             191.50   \n3               941               142             235.25   \n4               998               152             249.50   \n\n                                           embedding  \n0  [ 6.74242601e-02  9.02282074e-02 -5.09547768e-...  \n1  [ 5.52156083e-02  5.92139438e-02 -1.66167226e-...  \n2  [ 2.79801711e-02  3.39814313e-02 -2.06426643e-...  \n3  [ 6.82566911e-02  3.81274782e-02 -8.46855436e-...  \n4  [ 3.30264196e-02 -8.49765539e-03  9.57158115e-...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>sentence_chunk</th>\n      <th>chunk_char_count</th>\n      <th>chunk_word_count</th>\n      <th>chunk_token_count</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-39</td>\n      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n      <td>308</td>\n      <td>42</td>\n      <td>77.00</td>\n      <td>[ 6.74242601e-02  9.02282074e-02 -5.09547768e-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-38</td>\n      <td>Human Nutrition: 2020 Edition by University of...</td>\n      <td>210</td>\n      <td>30</td>\n      <td>52.50</td>\n      <td>[ 5.52156083e-02  5.92139438e-02 -1.66167226e-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-37</td>\n      <td>Contents Preface University of Hawai‘i at Māno...</td>\n      <td>766</td>\n      <td>114</td>\n      <td>191.50</td>\n      <td>[ 2.79801711e-02  3.39814313e-02 -2.06426643e-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-36</td>\n      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n      <td>941</td>\n      <td>142</td>\n      <td>235.25</td>\n      <td>[ 6.82566911e-02  3.81274782e-02 -8.46855436e-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-35</td>\n      <td>The Cardiovascular System University of Hawai‘...</td>\n      <td>998</td>\n      <td>152</td>\n      <td>249.50</td>\n      <td>[ 3.30264196e-02 -8.49765539e-03  9.57158115e-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:38:28.089920Z","iopub.execute_input":"2024-06-22T12:38:28.090552Z","iopub.status.idle":"2024-06-22T12:38:28.095851Z","shell.execute_reply.started":"2024-06-22T12:38:28.090516Z","shell.execute_reply":"2024-06-22T12:38:28.094803Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\ntext_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n\n# Convert texts and embedding df to list of dicts\npages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n\n# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\nembeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\nembeddings.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:39:20.835511Z","iopub.execute_input":"2024-06-22T12:39:20.835961Z","iopub.status.idle":"2024-06-22T12:39:21.295760Z","shell.execute_reply.started":"2024-06-22T12:39:20.835929Z","shell.execute_reply":"2024-06-22T12:39:21.294547Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"torch.Size([1680, 768])"},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import util, SentenceTransformer\n\nembedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n                                      device=device)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:39:25.205153Z","iopub.execute_input":"2024-06-22T12:39:25.205585Z","iopub.status.idle":"2024-06-22T12:39:26.250471Z","shell.execute_reply.started":"2024-06-22T12:39:25.205550Z","shell.execute_reply":"2024-06-22T12:39:26.249117Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step to peforming search\n\n# 1. Define the query\nquery = \"macronutrients functions\"\nprint(f\"Query: {query}\")\n\n# 2. Embed the query to the same numerical space as the text examples \nquery_embedding = embedding_model.encode(query, convert_to_tensor=True)\nquery_embedding","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:39:36.135400Z","iopub.execute_input":"2024-06-22T12:39:36.135785Z","iopub.status.idle":"2024-06-22T12:39:36.344410Z","shell.execute_reply.started":"2024-06-22T12:39:36.135756Z","shell.execute_reply":"2024-06-22T12:39:36.343338Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Query: macronutrients functions\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ef579e30484676807e57b30d91fdde"}},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor([ 3.6350e-02, -5.8203e-02, -1.8262e-02,  1.4228e-02,  1.3136e-02,\n         4.3278e-02, -3.3172e-02, -1.1831e-02, -4.3201e-02, -6.8741e-02,\n        -1.8463e-02, -1.5240e-02,  1.9626e-02,  4.7535e-02,  2.7343e-02,\n        -7.1382e-03,  1.0865e-02, -2.5707e-02, -7.7592e-02, -5.8880e-03,\n        -3.2791e-02,  2.0640e-02,  1.3843e-02, -6.2041e-03, -2.2706e-02,\n         3.9274e-02,  4.0431e-02,  5.1309e-03,  1.1578e-02, -1.1135e-02,\n        -1.9891e-02, -1.8691e-03, -4.9330e-02, -8.7934e-02,  1.5259e-06,\n        -3.3809e-02, -4.7408e-02,  1.7066e-02, -7.5259e-02,  3.4821e-02,\n         2.9377e-02, -3.2112e-02, -1.6509e-02,  7.3573e-03,  4.6359e-02,\n        -4.1220e-03,  1.4522e-02,  3.7190e-04, -6.3193e-02,  1.9782e-02,\n         2.9439e-02,  4.7811e-02,  1.6230e-02, -1.6853e-02,  2.3415e-02,\n         4.1553e-02,  8.8754e-03,  2.3375e-02, -3.9122e-02,  3.5091e-02,\n         6.1852e-02,  3.5322e-02, -1.1847e-03, -8.1968e-03,  4.3451e-02,\n         5.5786e-02, -2.3311e-02, -3.3593e-02, -2.1715e-03, -1.9097e-03,\n        -2.5364e-02, -1.3639e-02,  4.1690e-02,  4.0938e-02,  5.9997e-03,\n         1.8000e-02,  1.3215e-02, -8.1779e-02,  3.2166e-02,  1.9270e-02,\n         3.4942e-02,  1.9299e-02,  2.8515e-02,  1.0103e-02,  2.8328e-02,\n        -7.1241e-02, -6.0437e-03, -3.0819e-02, -1.4119e-02, -4.4822e-02,\n        -1.1033e-01, -1.4785e-02,  7.0766e-02,  3.6899e-02,  6.7770e-02,\n        -1.8671e-02,  2.6239e-02,  7.2633e-02,  6.7591e-02, -7.9518e-03,\n        -2.5954e-02,  2.3273e-02, -6.3832e-02,  1.3327e-02, -8.7793e-03,\n        -5.5085e-03, -1.2032e-02, -5.4448e-02, -5.0600e-03,  3.2773e-02,\n         1.9565e-03, -1.1326e-02, -2.7451e-03,  8.1029e-02, -2.3061e-02,\n         4.0297e-02, -1.1022e-02, -9.6865e-03, -1.8286e-02, -1.1952e-02,\n         4.1604e-02,  3.3237e-02,  1.9330e-02, -4.0204e-03, -7.4848e-03,\n         7.5033e-02, -5.2690e-03, -5.8149e-02,  4.9243e-03, -6.4739e-02,\n         6.3863e-03, -4.0424e-02,  1.2902e-03,  4.1638e-03, -9.1669e-03,\n         2.6458e-02,  3.6857e-02, -1.4164e-02,  5.1356e-03, -5.8743e-02,\n        -5.8676e-02, -4.6408e-02, -4.4494e-02,  6.6563e-03, -4.8885e-03,\n         1.2908e-02,  4.0277e-02,  1.0536e-01,  3.8002e-02,  3.6594e-02,\n         1.8698e-02,  2.1795e-02,  3.6478e-02,  2.7186e-02,  6.8002e-02,\n        -1.9822e-02,  6.7959e-02, -1.6065e-02, -5.4059e-03, -5.9769e-02,\n         3.7692e-02, -2.2915e-02, -6.9038e-02, -3.6363e-02, -1.4421e-02,\n         8.3935e-03,  9.0493e-02,  1.6174e-03, -5.1200e-03, -1.7809e-02,\n        -1.9112e-02, -3.2962e-02, -1.1321e-02,  5.8361e-03,  3.1491e-02,\n         2.5371e-02,  3.5389e-02, -1.8378e-02,  1.0811e-02, -1.0011e-02,\n         1.6314e-02,  3.1136e-02, -3.0903e-02,  3.3103e-02, -1.1536e-01,\n        -1.1217e-02, -3.7582e-02, -1.4941e-02,  4.1515e-02, -4.2493e-02,\n         6.2519e-02,  2.9420e-02, -5.4226e-03, -4.4830e-02,  1.0415e-02,\n         4.1465e-02,  1.8378e-02, -1.1811e-02,  7.9972e-03, -1.2710e-02,\n         1.4869e-02,  6.3483e-02, -3.8029e-02, -7.7649e-04, -5.1916e-02,\n         8.7794e-05,  1.2415e-02, -6.7691e-03,  7.4952e-03, -3.2907e-03,\n         3.1363e-02, -3.6003e-02,  1.4401e-02, -2.0461e-02,  3.2880e-02,\n        -5.4347e-02,  1.8641e-03, -3.0762e-02, -4.7269e-02,  5.4804e-02,\n         3.9552e-02, -7.6736e-03, -6.1100e-02, -5.7953e-02,  6.1746e-02,\n        -1.6355e-03, -6.1831e-04,  2.1462e-02, -6.6924e-02,  1.9964e-02,\n        -4.3563e-03,  7.1959e-02, -1.7868e-02, -8.3000e-03,  2.7443e-03,\n        -2.3884e-02, -2.3856e-02,  3.4985e-02, -6.8963e-03,  4.4980e-02,\n        -6.0062e-02, -1.9168e-02, -1.6593e-02,  1.6437e-03, -2.9701e-02,\n         3.2558e-02, -5.4387e-02, -5.1361e-02, -4.8482e-02,  2.6628e-02,\n        -7.3083e-04, -8.6868e-03,  2.3104e-02,  2.0880e-03,  8.9442e-03,\n         4.8725e-02,  7.1571e-02, -5.9714e-03, -2.7943e-02,  3.2549e-02,\n         2.5274e-02, -1.4486e-02,  2.3991e-02,  2.4127e-02, -3.6665e-02,\n        -4.1958e-02, -8.9344e-03,  4.1564e-04, -1.7625e-02, -1.9287e-02,\n         2.1600e-02,  4.0281e-02,  1.0630e-02,  6.9972e-02,  2.0331e-02,\n        -1.8336e-02,  7.4131e-03, -3.6774e-04, -9.2345e-03,  1.0167e-02,\n         1.3586e-02,  2.4319e-02,  3.3763e-03,  2.6211e-02,  1.3926e-02,\n        -3.3368e-02, -1.1845e-02,  5.7675e-02,  1.2245e-01, -4.2669e-02,\n         6.7766e-02,  2.9158e-03, -1.0134e-02, -1.3461e-02, -9.4241e-03,\n         1.9601e-02,  4.5678e-02, -3.1970e-03,  4.5957e-02, -6.6145e-03,\n        -4.8274e-02,  4.6692e-02, -4.2895e-02,  1.7429e-02, -2.1366e-02,\n         3.7164e-02, -8.2225e-04, -2.6790e-02,  4.1177e-02,  1.0538e-02,\n         1.4930e-02,  2.6115e-02, -1.2960e-02,  3.7944e-02,  1.0562e-02,\n        -1.9151e-03, -5.2271e-02,  1.6880e-02, -1.1220e-03, -3.2855e-02,\n         2.5690e-02, -4.4815e-02, -1.3548e-02, -3.0457e-02, -3.6349e-02,\n         4.5539e-03, -9.9191e-03,  5.0966e-02, -8.1343e-02,  1.9803e-02,\n        -3.9471e-02,  3.2549e-02,  2.2638e-02, -2.2977e-03,  6.2537e-02,\n         2.0651e-02, -3.1913e-02, -2.3974e-02,  3.2650e-02, -3.3222e-02,\n        -1.8187e-02, -3.1834e-02,  4.1767e-02,  1.3875e-02,  5.2768e-02,\n         9.1909e-03, -1.0872e-03,  1.0766e-02, -6.6975e-03,  1.5711e-02,\n         2.5503e-02, -3.7960e-02, -2.9142e-02,  2.9382e-02, -1.2938e-02,\n        -1.0852e-02,  2.2354e-03, -4.7183e-02, -7.3034e-02, -2.2891e-02,\n         4.2650e-02,  2.4176e-02, -1.1165e-01, -1.0147e-01,  8.0447e-02,\n         3.9282e-02, -3.6261e-02,  3.8353e-02, -1.4442e-02, -2.5609e-02,\n         2.1125e-02,  2.0547e-02, -1.5587e-02,  1.0468e-02, -2.0793e-02,\n         5.5583e-03,  3.8185e-02, -4.7569e-02, -5.9726e-02,  1.9571e-02,\n         4.0127e-03,  4.9266e-02,  4.4804e-02, -1.4215e-02,  1.3351e-02,\n        -3.0814e-02, -4.3726e-02,  2.0749e-02,  3.0552e-02, -5.4561e-02,\n         1.1927e-02, -9.7303e-02, -7.3809e-02,  5.3261e-02, -9.1812e-03,\n         1.8683e-02, -4.5561e-02,  6.5185e-03, -1.0684e-02,  3.2812e-02,\n         5.9706e-02, -1.1921e-02,  2.0189e-03, -4.9909e-03, -7.5257e-03,\n         8.0840e-03,  4.4026e-02,  7.8818e-03,  3.0287e-02,  4.3333e-02,\n         2.0462e-02, -5.2141e-02,  8.4779e-03, -1.6233e-02,  6.3627e-02,\n        -1.2433e-02,  1.1009e-03, -1.2066e-02,  3.7060e-02, -2.3903e-02,\n        -3.9463e-02, -1.6050e-02, -4.5603e-02,  3.2414e-02, -6.9709e-02,\n         1.5782e-02,  1.4140e-02,  1.2988e-02, -1.7289e-02,  6.6973e-02,\n         3.8294e-02, -3.4320e-02, -2.0565e-02,  1.9978e-02, -8.4692e-02,\n         3.0987e-02,  3.1848e-02, -4.9735e-02,  1.7842e-02,  2.0862e-02,\n         6.1948e-03,  3.2857e-02,  5.6972e-03, -1.1370e-02, -1.3293e-02,\n        -4.4083e-02, -3.2838e-02, -1.3895e-02,  3.6534e-02,  2.7387e-02,\n        -5.2431e-03,  6.8434e-02, -3.8091e-02,  8.3173e-02, -4.3943e-03,\n        -8.3881e-03,  1.4116e-03, -1.2041e-02,  1.9612e-02, -8.1738e-02,\n         1.6833e-02,  9.4147e-03,  1.5375e-02, -1.5650e-02, -4.6912e-02,\n         1.4058e-02,  7.0104e-02, -2.6923e-02, -3.3448e-02, -2.2285e-02,\n        -3.5100e-02,  2.0634e-02,  1.0727e-02, -1.1156e-02,  2.6671e-02,\n        -4.3746e-02, -2.6726e-02,  3.0730e-02, -3.9272e-03,  5.5360e-02,\n         4.7933e-03,  2.1723e-02,  1.8890e-02,  2.1489e-03, -2.8144e-03,\n         1.6298e-02, -3.5445e-03, -1.7373e-02, -9.3919e-03,  2.0933e-02,\n         3.4381e-02,  7.1752e-02, -3.8454e-03, -5.0130e-02,  2.3452e-02,\n         2.7063e-02,  2.6543e-02,  2.5106e-02,  3.1727e-02,  5.5437e-03,\n         5.9609e-02, -1.0850e-02, -1.5312e-02, -2.3866e-02,  1.7948e-02,\n         9.2929e-03, -1.7480e-02, -1.1611e-02, -2.6396e-02, -3.8142e-02,\n        -9.2148e-03, -4.9369e-03, -1.3283e-02,  5.4208e-02, -2.7172e-02,\n        -1.2256e-01,  1.0517e-02, -5.5937e-02,  1.0674e-02, -1.2129e-02,\n         1.5485e-02, -5.3038e-02,  2.1581e-03,  2.8599e-02,  4.5355e-02,\n         1.3345e-02,  3.1038e-02,  1.2068e-02, -3.2982e-02,  4.5370e-02,\n        -2.3381e-02, -3.5382e-02,  3.8439e-03, -6.0573e-03, -1.1817e-02,\n         5.8829e-02, -7.2229e-02,  8.4170e-02, -2.7791e-02,  1.6965e-02,\n         2.5487e-02, -2.7838e-02,  4.3995e-02,  2.7419e-02,  5.6940e-02,\n         1.3536e-02, -7.8063e-02, -4.0862e-02, -1.2517e-02, -6.0186e-02,\n        -4.6489e-02,  4.3929e-02, -2.6805e-02,  2.3045e-02,  6.7970e-02,\n        -5.2359e-33,  5.2046e-02, -6.7082e-02, -3.9935e-05,  1.0238e-01,\n         2.4979e-02,  8.1561e-02, -1.6367e-03, -1.6579e-02, -3.1610e-02,\n         4.6972e-03,  3.4900e-02, -6.5220e-03,  9.2133e-03, -4.3292e-02,\n        -2.9737e-03, -2.4475e-02,  5.7400e-03, -1.8522e-02,  3.0956e-03,\n        -2.1347e-02, -3.4688e-02, -1.1564e-02, -2.7849e-03,  4.7683e-02,\n         1.2937e-02, -1.1162e-02,  6.7933e-03,  4.0392e-02, -5.5596e-02,\n         4.1731e-02,  6.9013e-03,  1.3235e-02, -2.1169e-02,  2.5780e-02,\n        -1.1397e-02,  2.2703e-02, -3.5258e-02, -6.5036e-03,  5.1972e-02,\n        -2.7838e-02, -8.3761e-02, -2.4183e-02,  9.5083e-03,  4.3265e-03,\n        -5.2396e-03,  2.5368e-02, -4.4687e-02, -1.6778e-02,  1.7937e-03,\n         7.0405e-02, -1.4708e-02,  3.4635e-02, -1.7993e-02,  7.0235e-02,\n         1.1179e-02,  5.6379e-02,  1.9461e-02, -4.2848e-02,  5.8889e-02,\n        -3.7263e-02,  2.8347e-02,  5.9297e-02,  2.4760e-03,  3.8594e-02,\n         8.1166e-03, -6.0620e-03,  1.3865e-02,  1.0721e-02, -2.9954e-02,\n        -1.2227e-02, -2.9674e-02, -5.4035e-02,  3.5945e-02, -3.5790e-03,\n        -2.6835e-02, -6.8260e-02, -1.8446e-02,  2.9967e-02, -4.5362e-02,\n        -2.6699e-02, -1.1517e-02, -1.9235e-02,  1.9823e-02, -2.6917e-02,\n        -2.2139e-02,  1.5205e-03, -8.2441e-04,  3.6219e-03, -7.2804e-03,\n        -3.8944e-02, -4.0059e-03,  8.9619e-02,  6.6004e-03,  1.2463e-03,\n         5.9522e-02, -1.4255e-02,  3.9081e-02,  2.6939e-03, -9.6303e-03,\n        -4.4596e-02, -5.1747e-03,  2.2760e-02,  1.2890e-02, -3.3263e-02,\n        -1.0907e-02, -2.5837e-02, -5.9987e-02, -1.6392e-02,  9.5916e-03,\n        -3.6946e-02, -1.3986e-02,  1.1129e-02,  4.9195e-02, -3.9620e-02,\n        -4.6434e-02,  7.5271e-03,  8.6060e-03,  1.4557e-02,  3.2561e-02,\n        -2.4884e-02, -3.9581e-02,  1.8327e-02,  3.8874e-02, -3.5615e-02,\n        -1.3830e-02, -4.0152e-02,  4.0546e-02,  3.6840e-02, -6.5699e-04,\n         5.3292e-02,  1.7416e-02,  4.0632e-02,  2.2873e-07,  1.1094e-02,\n         1.8339e-03,  1.8760e-02, -6.6481e-02, -2.2438e-02, -5.2669e-02,\n         6.8776e-04, -1.1481e-02, -1.8437e-02,  6.0199e-03,  7.4666e-02,\n        -6.9812e-02, -3.6983e-03, -9.0829e-03,  4.5065e-02,  1.4773e-02,\n        -5.1455e-03, -1.0032e-01,  5.3270e-02,  1.0136e-02, -8.9594e-02,\n        -1.9746e-02, -7.1009e-02,  2.3010e-02, -4.2884e-02, -3.5130e-02,\n         4.9862e-03, -2.2965e-02,  5.6315e-02,  1.1485e-03,  7.8967e-02,\n         4.4106e-02,  1.6735e-02,  9.2410e-03, -4.0429e-02,  1.0647e-02,\n        -9.9561e-03,  1.3421e-02, -3.4894e-03, -3.3250e-03, -3.4336e-02,\n        -3.0697e-02, -9.2931e-03, -1.6855e-02, -3.2713e-02, -4.1040e-02,\n        -3.4477e-02, -1.6579e-02,  7.0743e-03,  8.2713e-03, -4.0951e-02,\n        -5.3731e-04, -4.7156e-02,  2.9803e-02, -2.0100e-02,  2.8285e-02,\n         1.8084e-02,  5.1569e-02,  4.4442e-02,  1.0310e-02, -1.8038e-02,\n        -1.6200e-02,  1.6763e-03,  7.6825e-03,  2.8997e-02,  3.3238e-02,\n        -3.1750e-02,  1.8266e-34, -1.5178e-03, -3.0013e-02,  3.0899e-02,\n        -4.2527e-02,  1.6324e-02,  7.9889e-03, -1.0713e-01,  4.5577e-03,\n        -3.1919e-03, -4.4338e-02, -4.6318e-02], device='cuda:0')"},"metadata":{}}]},{"cell_type":"markdown","source":"* For similarity -> not used cosine similarity, used dot product\n\nOnly difference in cosine sim and dot product is, cosine sim has normalization step, but we are already getting normalized embeddings from our embedding model\n\n#### Dot Product\n* Measure of magnitude and direction between two vectors\n* Vectors that are aligned in direction and magnitude have a higher positive value\n* Vectors that are opposite in direction and magnitude have a higher negative value","metadata":{}},{"cell_type":"code","source":"# 3. Get similarity scores with the dot product (we'll time this for fun)\nfrom time import perf_counter as timer\n\nstart_time = timer()\ndot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\nend_time = timer()\n\nprint(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n\n# 4. Get the top-k results (we'll keep this to 5)\ntop_results_dot_product = torch.topk(dot_scores, k=5)\ntop_results_dot_product","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:41:48.427082Z","iopub.execute_input":"2024-06-22T12:41:48.428011Z","iopub.status.idle":"2024-06-22T12:41:48.508996Z","shell.execute_reply.started":"2024-06-22T12:41:48.427967Z","shell.execute_reply":"2024-06-22T12:41:48.507541Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Time take to get scores on 1680 embeddings: 0.00385 seconds.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.return_types.topk(\nvalues=tensor([0.6926, 0.6738, 0.6646, 0.6536, 0.6473], device='cuda:0'),\nindices=tensor([42, 47, 41, 51, 46], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"# Define helper function to print wrapped text, so it doesn't print a whole text chunk as a single line \nimport textwrap\n\ndef print_wrapped(text, wrap_length=80):\n    wrapped_text = textwrap.fill(text, wrap_length)\n    print(wrapped_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:44:07.636244Z","iopub.execute_input":"2024-06-22T12:44:07.637348Z","iopub.status.idle":"2024-06-22T12:44:07.643210Z","shell.execute_reply.started":"2024-06-22T12:44:07.637305Z","shell.execute_reply":"2024-06-22T12:44:07.641826Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(f\"Query: '{query}'\\n\")\nprint(\"Results:\")\n# Loop through zipped together scores and indicies from torch.topk\nfor score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n    print(f\"Score: {score:.4f}\")\n    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n    print(\"Text:\")\n    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n    # Print the page number too so we can reference the textbook further (and check the results)\n    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:44:45.044460Z","iopub.execute_input":"2024-06-22T12:44:45.045685Z","iopub.status.idle":"2024-06-22T12:44:45.060742Z","shell.execute_reply.started":"2024-06-22T12:44:45.045637Z","shell.execute_reply":"2024-06-22T12:44:45.059523Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Query: 'macronutrients functions'\n\nResults:\nScore: 0.6926\nText:\nMacronutrients Nutrients that are needed in large amounts are called\nmacronutrients. There are three classes of macronutrients: carbohydrates,\nlipids, and proteins. These can be metabolically processed into cellular energy.\nThe energy from macronutrients comes from their chemical bonds. This chemical\nenergy is converted into cellular energy that is then utilized to perform work,\nallowing our bodies to conduct their basic functions. A unit of measurement of\nfood energy is the calorie. On nutrition food labels the amount given for\n“calories” is actually equivalent to each calorie multiplied by one thousand. A\nkilocalorie (one thousand calories, denoted with a small “c”) is synonymous with\nthe “Calorie” (with a capital “C”) on nutrition food labels. Water is also a\nmacronutrient in the sense that you require a large amount of it, but unlike the\nother macronutrients, it does not yield calories. Carbohydrates Carbohydrates\nare molecules composed of carbon, hydrogen, and oxygen.\nPage number: 5\n\n\nScore: 0.6738\nText:\nWater There is one other nutrient that we must have in large quantities: water.\nWater does not contain carbon, but is composed of two hydrogens and one oxygen\nper molecule of water. More than 60 percent of your total body weight is water.\nWithout it, nothing could be transported in or out of the body, chemical\nreactions would not occur, organs would not be cushioned, and body temperature\nwould fluctuate widely. On average, an adult consumes just over two liters of\nwater per day from food and drink combined. Since water is so critical for\nlife’s basic processes, the amount of water input and output is supremely\nimportant, a topic we will explore in detail in Chapter 4. Micronutrients\nMicronutrients are nutrients required by the body in lesser amounts, but are\nstill essential for carrying out bodily functions. Micronutrients include all\nthe essential minerals and vitamins. There are sixteen essential minerals and\nthirteen vitamins (See Table 1.1 “Minerals and Their Major Functions” and Table\n1.2 “Vitamins and Their Major Functions” for a complete list and their major\nfunctions). In contrast to carbohydrates, lipids, and proteins, micronutrients\nare not sources of energy (calories), but they assist in the process as\ncofactors or components of enzymes (i.e., coenzymes).\nPage number: 8\n\n\nScore: 0.6646\nText:\nLearning Objectives By the end of this chapter, you will be able to: • Describe\nbasic concepts in nutrition • Describe factors that affect your nutritional\nneeds • Describe the importance of research and scientific methods to\nunderstanding nutrition What are Nutrients? The foods we eat contain nutrients.\nNutrients are substances required by the body to perform its basic functions.\nNutrients must be obtained from our diet, since the human body does not\nsynthesize or produce them. Nutrients have one or more of three basic functions:\nthey provide energy, contribute to body structure, and/or regulate chemical\nprocesses in the body. These basic functions allow us to detect and respond to\nenvironmental surroundings, move, excrete wastes, respire (breathe), grow, and\nreproduce. There are six classes of nutrients required for the body to function\nand maintain overall health. These are carbohydrates, lipids, proteins, water,\nvitamins, and minerals. Foods also contain non-nutrients that may be harmful\n(such as natural toxins common in plant foods and additives like some dyes and\npreservatives) or beneficial (such as antioxidants). 4 | Introduction\nPage number: 4\n\n\nScore: 0.6536\nText:\nVitamins Major Functions Water-soluble Thiamin (B1) Coenzyme, energy metabolism\nassistance Riboflavin (B2 ) Coenzyme, energy metabolism assistance Niacin (B3)\nCoenzyme, energy metabolism assistance Pantothenic acid (B5) Coenzyme, energy\nmetabolism assistance Pyridoxine (B6) Coenzyme, amino acid synthesis assistance\nBiotin (B7) Coenzyme, amino acid and fatty acid metabolism Folate (B9) Coenzyme,\nessential for growth Cobalamin (B12) Coenzyme, red blood cell synthesis C\n(ascorbic acid) Collagen synthesis, antioxidant Fat-soluble A Vision,\nreproduction, immune system function D Bone and teeth health maintenance, immune\nsystem function E Antioxidant, cell membrane protection K Bone and teeth health\nmaintenance, blood clotting Vitamin deficiencies can cause severe health\nproblems and even death. For example, a deficiency in niacin causes a disease\ncalled pellagra, which was common in the early twentieth century in some parts\nof America. The common signs and symptoms of pellagra are known as the\n“4D’s—diarrhea, dermatitis, dementia, and death.” Until scientists found out\nthat better diets relieved the signs and symptoms of pellagra, many people with\nthe disease ended up hospitalized in insane asylums awaiting death. Other\nvitamins were also found to prevent certain disorders and diseases such as\nscurvy (vitamin C), night blindness vitamin A, and rickets (vitamin D). Table\n1.3 Functions of Nutrients Introduction | 11\nPage number: 11\n\n\nScore: 0.6473\nText:\nFigure 1.1 The Macronutrie nts: Carbohydrat es, Lipids, Protein, and Water\nProteins Proteins are macromolecules composed of chains of subunits called amino\nacids. Amino acids are simple subunits composed of carbon, oxygen, hydrogen, and\nnitrogen. Food sources of proteins include meats, dairy products, seafood, and a\nvariety of different plant- based foods, most notably soy. The word protein\ncomes from a Greek word meaning “of primary importance,” which is an apt\ndescription of these macronutrients; they are also known colloquially as the\n“workhorses” of life. Proteins provide four kilocalories of energy per gram;\nhowever providing energy is not protein’s most important function. Proteins\nprovide structure to bones, muscles and skin, and play a role in conducting most\nof the chemical reactions that take place in the body. Scientists estimate that\ngreater than one-hundred thousand different proteins exist within the human\nbody. The genetic codes in DNA are basically protein recipes that determine the\norder in which 20 different amino acids are bound together to make thousands of\nspecific proteins. Figure 1.1 The Macronutrients: Carbohydrates, Lipids,\nProtein, and Water Introduction | 7\nPage number: 7\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Functions for the pipeline","metadata":{}},{"cell_type":"code","source":"def retrieve_relevant_resources(query: str,\n                                embeddings: torch.tensor,\n                                model: SentenceTransformer=embedding_model,\n                                n_resources_to_return: int=5,\n                                print_time: bool=True):\n    \"\"\"\n    Embeds a query with model and returns top k scores and indices from embeddings.\n    \"\"\"\n\n    # Embed the query\n    query_embedding = model.encode(query, \n                                   convert_to_tensor=True) \n\n    # Get dot product scores on embeddings\n    start_time = timer()\n    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n    end_time = timer()\n\n    if print_time:\n        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n\n    scores, indices = torch.topk(input=dot_scores, \n                                 k=n_resources_to_return)\n\n    return scores, indices\n\ndef print_top_results_and_scores(query: str,\n                                 embeddings: torch.tensor,\n                                 pages_and_chunks: list[dict]=pages_and_chunks,\n                                 n_resources_to_return: int=5):\n    \"\"\"\n    Takes a query, retrieves most relevant resources and prints them out in descending order.\n\n    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n    \"\"\"\n    \n    scores, indices = retrieve_relevant_resources(query=query,\n                                                  embeddings=embeddings,\n                                                  n_resources_to_return=n_resources_to_return)\n    \n    print(f\"Query: {query}\\n\")\n    print(\"Results:\")\n    # Loop through zipped together scores and indicies\n    for score, index in zip(scores, indices):\n        print(f\"Score: {score:.4f}\")\n        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n        # Print the page number too so we can reference the textbook further and check the results\n        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n        print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:57:29.883586Z","iopub.execute_input":"2024-06-22T12:57:29.884518Z","iopub.status.idle":"2024-06-22T12:57:29.896090Z","shell.execute_reply.started":"2024-06-22T12:57:29.884481Z","shell.execute_reply":"2024-06-22T12:57:29.894938Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"query = \"symptoms of pellagra\"\n\n# Get just the scores and indices of top related results\nscores, indices = retrieve_relevant_resources(query=query,\n                                              embeddings=embeddings)\nscores, indices","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:57:30.909611Z","iopub.execute_input":"2024-06-22T12:57:30.910307Z","iopub.status.idle":"2024-06-22T12:57:30.963569Z","shell.execute_reply.started":"2024-06-22T12:57:30.910257Z","shell.execute_reply":"2024-06-22T12:57:30.962427Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf1d2d09c034f4fb6845cf4e0d8e387"}},"metadata":{}},{"name":"stdout","text":"[INFO] Time taken to get scores on 1680 embeddings: 0.00027 seconds.\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(tensor([0.5000, 0.3741, 0.2959, 0.2793, 0.2721], device='cuda:0'),\n tensor([ 822,  853, 1536, 1555, 1531], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"# Print out the texts of the top scores\nprint_top_results_and_scores(query=query,\n                             embeddings=embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:57:47.273258Z","iopub.execute_input":"2024-06-22T12:57:47.274110Z","iopub.status.idle":"2024-06-22T12:57:47.323107Z","shell.execute_reply.started":"2024-06-22T12:57:47.274072Z","shell.execute_reply":"2024-06-22T12:57:47.322026Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f4b4bf9c884bf6829a3ebac0ab4cc4"}},"metadata":{}},{"name":"stdout","text":"[INFO] Time taken to get scores on 1680 embeddings: 0.00017 seconds.\nQuery: symptoms of pellagra\n\nResults:\nScore: 0.5000\nNiacin deficiency is commonly known as pellagra and the symptoms include\nfatigue, decreased appetite, and indigestion.  These symptoms are then commonly\nfollowed by the four D’s: diarrhea, dermatitis, dementia, and sometimes death.\nFigure 9.12  Conversion of Tryptophan to Niacin Water-Soluble Vitamins | 565\nPage number: 565\n\n\nScore: 0.3741\ncar. Does it drive faster with a half-tank of gas or a full one?It does not\nmatter; the car drives just as fast as long as it has gas. Similarly, depletion\nof B vitamins will cause problems in energy metabolism, but having more than is\nrequired to run metabolism does not speed it up. Buyers of B-vitamin supplements\nbeware; B vitamins are not stored in the body and all excess will be flushed\ndown the toilet along with the extra money spent. B vitamins are naturally\npresent in numerous foods, and many other foods are enriched with them. In the\nUnited States, B-vitamin deficiencies are rare; however in the nineteenth\ncentury some vitamin-B deficiencies plagued many people in North America. Niacin\ndeficiency, also known as pellagra, was prominent in poorer Americans whose main\ndietary staple was refined cornmeal. Its symptoms were severe and included\ndiarrhea, dermatitis, dementia, and even death. Some of the health consequences\nof pellagra are the result of niacin being in insufficient supply to support the\nbody’s metabolic functions.\nPage number: 591\n\n\nScore: 0.2959\nThe carbon dioxide gas bubbles infiltrate the stretchy gluten, giving bread its\nporosity and tenderness. For those who are sensitive to gluten, it is good to\nknow that corn, millet, buckwheat, and oats do not contain the proteins that\nmake gluten. However, some people who have celiac disease also may have a\nresponse to products containing oats. This is most likely the result of cross-\ncontamination of grains during harvest, storage, packaging, and processing.\nCeliac disease is most common in people of European descent and is rare in\npeople of African American, Japanese, and Chinese descent. It is much more\nprevalent in women and in people with Type 1 diabetes, autoimmune thyroid\ndisease, and Down and Turner syndromes. Symptoms can range from mild to severe\nand can include pale, fatty, loose stools, gastrointestinal upset, abdominal\npain, weight loss and, in children, a failure to grow and thrive. The symptoms\ncan appear in infancy or much later in life, even Nutrition, Health and Disease\n| 1079\nPage number: 1079\n\n\nScore: 0.2793\nImage by BruceBlaus/ CC BY 4.0 When the vertebral bone tissue is weakened, it\ncan cause the spine to curve. The increase in spine curvature not only causes\npain, but also decreases a person’s height. Curvature of the upper spine\nproduces what is called Dowager’s hump, also known as kyphosis. Severe upper-\nspine deformity can compress the chest cavity and cause difficulty breathing. It\nmay also cause abdominal pain and loss of appetite because of the increased\npressure on the abdomen. 1090 | Nutrition, Health and Disease\nPage number: 1090\n\n\nScore: 0.2721\nesophagus and cause irritation. It is estimated that GERD affects 25 to 35\npercent of the US population. An analysis of several studies published in the\nAugust 2005 issue of Annals of Internal Medicine concludes that GERD is much\nmore prevalent in people who are obese.1 The most common GERD symptom is\nheartburn, but people with GERD may also experience regurgitation (flow of the\nstomach’s acidic contents into the mouth), frequent coughing, and trouble\nswallowing. There are other causative factors of GERD that may be separate from\nor intertwined with obesity. The sphincter that separates the stomach’s internal\ncontents from the esophagus often does not function properly and acidic gastric\ncontents seep upward. Sometimes the peristaltic contractions of the esophagus\nare also sluggish and compromise the clearance of acidic contents. In addition\nto having an unbalanced, high-fat diet, some people with GERD are sensitive to\nparticular foods—chocolate, garlic, spicy foods, fried foods, and tomato-based\nfoods—which worsen symptoms. Drinks containing alcohol or caffeine may also\nworsen GERD symptoms. GERD is diagnosed most often by a history of the frequency\nof recurring symptoms. A more proper diagnosis can be made when a doctor inserts\na small device into the lower esophagus that measures the acidity of the\ncontents during one’s daily activities.\nPage number: 1077\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}